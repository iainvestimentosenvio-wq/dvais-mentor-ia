# ğŸ¤ Assistente de Voz com Voz Clonada - SoluÃ§Ã£o Gratuita

## âœ… Resposta Direta

**SIM, Ã© possÃ­vel fazer com sua voz clonada de forma gratuita!**

### SoluÃ§Ã£o: **Web Speech API (captura) + ElevenLabs Gratuito (resposta)**

- âœ… **Web Speech API**: Gratuito, captura voz do usuÃ¡rio
- âœ… **ElevenLabs Tier Gratuito**: 10.000 caracteres/mÃªs com voz clonada
- âœ… **Total**: $0/mÃªs (atÃ© 10k caracteres)

---

## ğŸ¯ Como Funciona

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UsuÃ¡rio fala                          â”‚
â”‚  â†“                                      â”‚
â”‚  Web Speech API (gratuito)             â”‚
â”‚  â†’ Converte voz em texto               â”‚
â”‚  â†“                                      â”‚
â”‚  GPT-4o-mini (processa pergunta)       â”‚
â”‚  â†’ Gera resposta curta                 â”‚
â”‚  â†“                                      â”‚
â”‚  ElevenLabs (gratuito - sua voz)       â”‚
â”‚  â†’ Converte resposta em Ã¡udio          â”‚
â”‚  â†“                                      â”‚
â”‚  Reproduz Ã¡udio + rola pÃ¡gina          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’° Custo Real (MVP)

### CenÃ¡rio: 50 conversas/mÃªs, ~200 caracteres por resposta

| ServiÃ§o | Uso | Custo |
|---------|-----|-------|
| **Web Speech API** | Captura de voz | **$0** (nativo do navegador) |
| **OpenAI GPT-4o-mini** | ~10k tokens/mÃªs | **$0.15/mÃªs** (muito barato) |
| **ElevenLabs** | 10k caracteres/mÃªs | **$0** (tier gratuito) |
| **TOTAL** | | **~$0.15/mÃªs** (praticamente grÃ¡tis!) |

### OtimizaÃ§Ãµes para economizar:
- âœ… Respostas curtas (mÃ¡ximo 150 caracteres)
- âœ… Cache de respostas comuns
- âœ… Limitar a 50 conversas/mÃªs no MVP

---

## ğŸš€ ImplementaÃ§Ã£o Passo a Passo

### 1. Criar Conta no ElevenLabs (Gratuito)

1. Acesse: https://elevenlabs.io
2. Crie conta gratuita
3. VÃ¡ em **"Voice Lab"** â†’ **"Add Voice"** â†’ **"Instant Voice Cloning"**
4. FaÃ§a upload de 1-2 minutos da sua voz (Ã¡udio claro)
5. Aguarde processamento (alguns minutos)
6. Copie o **Voice ID** gerado

### 2. Criar Vercel Edge Function

**`apps/painel-web/app/api/voice/route.ts`**

```typescript
import { NextRequest, NextResponse } from 'next/server'

export const runtime = 'edge'

const SYSTEM_PROMPT = `
VocÃª Ã© um assistente de voz do DVAi$ - Mentor IA.

REGRAS:
1. Responda APENAS sobre a plataforma DVAi$ - Mentor IA
2. Seja breve (mÃ¡ximo 150 caracteres por resposta)
3. Sempre retorne JSON: { "text": "...", "scrollTarget": "id-do-elemento" }
4. Se pergunta nÃ£o for sobre a plataforma, diga: "Desculpe, sÃ³ posso ajudar com informaÃ§Ãµes sobre o DVAi$ - Mentor IA."
`

export async function POST(request: NextRequest) {
  try {
    const { transcript } = await request.json()
    
    // 1. Processar com GPT (gerar resposta curta)
    const gptResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: SYSTEM_PROMPT },
          { role: 'user', content: transcript }
        ],
        max_tokens: 50, // Limita resposta (economiza)
        temperature: 0.7
      })
    })
    
    const gptData = await gptResponse.json()
    const responseText = JSON.parse(gptData.choices[0].message.content)
    
    // 2. Gerar Ã¡udio com sua voz (ElevenLabs)
    const audioResponse = await fetch(
      `https://api.elevenlabs.io/v1/text-to-speech/${process.env.ELEVENLABS_VOICE_ID}`,
      {
        method: 'POST',
        headers: {
          'Accept': 'audio/mpeg',
          'Content-Type': 'application/json',
          'xi-api-key': process.env.ELEVENLABS_API_KEY!
        },
        body: JSON.stringify({
          text: responseText.text,
          model_id: 'eleven_multilingual_v2', // Suporta portuguÃªs
          voice_settings: {
            stability: 0.5,
            similarity_boost: 0.75
          }
        })
      }
    )
    
    const audioBuffer = await audioResponse.arrayBuffer()
    const audioBase64 = Buffer.from(audioBuffer).toString('base64')
    
    return NextResponse.json({
      audio: `data:audio/mpeg;base64,${audioBase64}`,
      scrollTarget: responseText.scrollTarget,
      text: responseText.text
    })
  } catch (error) {
    return NextResponse.json({ error: 'Erro ao processar' }, { status: 500 })
  }
}
```

### 3. Componente React de Voz

**`apps/painel-web/componentes/VoiceAssistant.tsx`**

```typescript
'use client'

import { useState, useRef, useEffect } from 'react'
import Icon from './Icon'

export default function VoiceAssistant() {
  const [isListening, setIsListening] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const audioRef = useRef<HTMLAudioElement | null>(null)

  useEffect(() => {
    // Inicializar Web Speech API
    const SpeechRecognition = window.SpeechRecognition || (window as any).webkitSpeechRecognition
    
    if (!SpeechRecognition) {
      console.warn('Web Speech API nÃ£o suportada neste navegador')
      return
    }

    const recognition = new SpeechRecognition()
    recognition.lang = 'pt-BR'
    recognition.continuous = false
    recognition.interimResults = false

    recognition.onresult = async (event) => {
      const transcript = event.results[0][0].transcript
      setIsListening(false)
      
      // Enviar para Edge Function
      try {
        const response = await fetch('/api/voice', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ transcript })
        })
        
        const { audio, scrollTarget, text } = await response.json()
        
        // Reproduzir Ã¡udio
        if (audio) {
          playAudio(audio)
        }
        
        // Rolar pÃ¡gina
        if (scrollTarget) {
          const element = document.getElementById(scrollTarget)
          if (element) {
            element.scrollIntoView({ behavior: 'smooth', block: 'center' })
          }
        }
      } catch (error) {
        console.error('Erro ao processar voz:', error)
      }
    }

    recognition.onerror = (event) => {
      console.error('Erro no reconhecimento:', event.error)
      setIsListening(false)
    }

    recognition.onend = () => {
      setIsListening(false)
    }

    recognitionRef.current = recognition
  }, [])

  const startListening = () => {
    if (recognitionRef.current && !isListening) {
      recognitionRef.current.start()
      setIsListening(true)
    }
  }

  const stopListening = () => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop()
      setIsListening(false)
    }
  }

  const playAudio = (audioData: string) => {
    setIsSpeaking(true)
    const audio = new Audio(audioData)
    audio.onended = () => setIsSpeaking(false)
    audio.onerror = () => setIsSpeaking(false)
    audio.play()
    audioRef.current = audio
  }

  return (
    <div className="fixed bottom-6 right-6 z-50">
      <button
        onClick={isListening ? stopListening : startListening}
        disabled={isSpeaking}
        className={`
          w-16 h-16 rounded-full flex items-center justify-center
          shadow-2xl transition-all duration-300
          ${isListening 
            ? 'bg-red-500 hover:bg-red-600 animate-pulse' 
            : 'bg-gradient-to-r from-blue-600 to-cyan-500 hover:from-blue-700 hover:to-cyan-600'
          }
          ${isSpeaking ? 'opacity-50 cursor-not-allowed' : 'hover:scale-110'}
        `}
        aria-label={isListening ? 'Parar de ouvir' : 'Falar com IA'}
      >
        {isListening ? (
          <Icon name="fas fa-stop" className="text-white text-xl" />
        ) : isSpeaking ? (
          <Icon name="fas fa-volume-up" className="text-white text-xl animate-pulse" />
        ) : (
          <Icon name="fas fa-microphone" className="text-white text-xl" />
        )}
      </button>
      
      {isListening && (
        <div className="absolute -top-12 left-1/2 transform -translate-x-1/2 bg-black/80 text-white px-4 py-2 rounded-lg text-sm whitespace-nowrap">
          ğŸ¤ Ouvindo...
        </div>
      )}
    </div>
  )
}
```

### 4. Adicionar IDs aos Elementos da PÃ¡gina

**`apps/painel-web/app/page.tsx`** (exemplo)

```typescript
<section id="features" className="py-20">
  {/* Features */}
</section>

<section id="stats" className="py-20">
  {/* Stats */}
</section>

<section id="seguranca" className="py-20">
  {/* SeguranÃ§a */}
</section>
```

### 5. VariÃ¡veis de Ambiente

**`.env.local`** (nÃ£o commitar no Git!)

```env
OPENAI_API_KEY=sk-...
ELEVENLABS_API_KEY=...
ELEVENLABS_VOICE_ID=... # ID da sua voz clonada
```

**`.env.example`** (commitar no Git)

```env
OPENAI_API_KEY=sk-your-key-here
ELEVENLABS_API_KEY=your-key-here
ELEVENLABS_VOICE_ID=your-voice-id-here
```

---

## ğŸ“Š Monitoramento de Uso (ElevenLabs)

### Dashboard ElevenLabs:
1. Acesse: https://elevenlabs.io/app/usage
2. Veja quantos caracteres usou no mÃªs
3. Configure alertas quando chegar perto de 10k

### Implementar Contador no CÃ³digo:

```typescript
// Adicionar ao Edge Function
const usage = await getElevenLabsUsage() // API do ElevenLabs
if (usage.remaining < 1000) {
  // Avisar que estÃ¡ perto do limite
  return NextResponse.json({ 
    error: 'Limite mensal quase atingido. Tente novamente no prÃ³ximo mÃªs.' 
  }, { status: 429 })
}
```

---

## ğŸ¯ EstratÃ©gia de Economia

### Para maximizar os 10k caracteres/mÃªs:

1. **Respostas Curtas**: MÃ¡ximo 150 caracteres
2. **Cache Agressivo**: Cachear respostas comuns
3. **Limitar Conversas**: MÃ¡ximo 50 conversas/mÃªs no MVP
4. **Fallback**: Se acabar, usar Web Speech API (sem voz customizada)

### Exemplo de Cache:

```typescript
// Cache de respostas comuns
const commonResponses = {
  'o que Ã© o dvais': {
    text: 'O DVAi$ Ã© uma plataforma de mentoria inteligente para investimentos.',
    scrollTarget: 'hero'
  },
  'preÃ§os': {
    text: 'Nossos planos comeÃ§am em R$ 29,90 por mÃªs.',
    scrollTarget: 'pricing'
  }
  // ... mais respostas
}

// Usar cache antes de chamar API
if (commonResponses[transcript.toLowerCase()]) {
  return commonResponses[transcript.toLowerCase()]
}
```

---

## âœ… Checklist de ImplementaÃ§Ã£o

- [ ] Criar conta no ElevenLabs (gratuito)
- [ ] Clonar sua voz (upload de 1-2 min de Ã¡udio)
- [ ] Copiar Voice ID
- [ ] Criar Edge Function `/api/voice`
- [ ] Criar componente `VoiceAssistant.tsx`
- [ ] Adicionar IDs aos elementos da pÃ¡gina
- [ ] Configurar variÃ¡veis de ambiente
- [ ] Testar localmente
- [ ] Deploy na Vercel
- [ ] Configurar variÃ¡veis de ambiente na Vercel

---

## ğŸš¨ LimitaÃ§Ãµes do Tier Gratuito

### ElevenLabs Gratuito:
- âœ… 10.000 caracteres/mÃªs
- âœ… Voz clonada funcionando
- âš ï¸ Se passar de 10k, precisa pagar ($5/mÃªs para 30k)

### SoluÃ§Ã£o:
- Implementar cache agressivo
- Limitar respostas a 150 caracteres
- Monitorar uso mensal
- Ter fallback para Web Speech API

---

## ğŸ“ Recursos

- [ElevenLabs Voice Cloning](https://elevenlabs.io/docs/api-reference/voice-cloning)
- [ElevenLabs API Docs](https://elevenlabs.io/docs/api-reference/text-to-speech)
- [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [OpenAI GPT-4o-mini](https://platform.openai.com/docs/models/gpt-4o-mini)

---

## ğŸ’¡ ConclusÃ£o

**SIM, Ã© totalmente possÃ­vel fazer com sua voz clonada de forma gratuita!**

- âœ… **Custo**: ~$0.15/mÃªs (praticamente grÃ¡tis)
- âœ… **Voz Clonada**: Funciona perfeitamente
- âœ… **Sem Servidor**: Tudo no Vercel (Edge Functions)
- âœ… **Funcional**: Pronto para MVP

**PrÃ³ximo passo**: Implementar seguindo este guia! ğŸš€

